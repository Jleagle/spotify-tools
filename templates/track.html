{{define "track"}} {{ template "header" .}}

<a class="btn btn-success float-right" target="_blank" href="https://open.spotify.com/track/{{ .Track.ID }}">View on Spotify</a>

<h1 id="h1">{{ .Track.Name }}</h1>

<p><strong>Artists:</strong> {{artists .Track.Artists}}</p>
<p><strong>Album:</strong> <a href="/album/{{.Track.Album.ID}}">{{.Track.Album.Name}}</a></p>
<p><strong>Popularity:</strong> {{ .Track.Popularity }}/100</p>
<p class="clearfix">
    <span style="float: left"><strong>Preview:</strong> </span>
    <audio controls style="float: left">
        <source src="{{.Track.PreviewURL}}" type="audio/mpeg">
    </audio>
</p>
<p><strong>Duration:</strong> {{ seconds .AudioFeatures.Duration }}</p>
<p><strong>Key:</strong> {{ .AudioFeatures.Key }} - 0 = C, 1 = C♯/D♭, 2 = D.</p>
<p><strong>Loudness:</strong> {{ .AudioFeatures.Loudness }} decibels</p>
<p><strong>Mode:</strong> {{ if eq .AudioFeatures.Mode 1 }}Major{{else}}Minor{{end}}</p>
<p><strong>Tempo:</strong> {{ .AudioFeatures.Tempo }} beats per minute</p>
<p><strong>Time Signature:</strong> {{ .AudioFeatures.TimeSignature }} beats are in each bar</p>

<h4>Audio Features</h4>
<div id="chart"></div>

<script type="text/javascript" src="https://www.gstatic.com/charts/loader.js"></script>
<script type="text/javascript">
    google.charts.load('current', {packages: ['corechart', 'bar']});
    google.charts.setOnLoadCallback(drawBasic);

    function drawBasic() {
        var data = new google.visualization.DataTable();
        data.addColumn('string', 'Feature');
        data.addColumn('number', 'Percent');
        data.addColumn({type: 'string', role: 'tooltip'});
        data.addRows([
            ['Acousticness', {{ .AudioFeatures.Acousticness }}, 'A confidence measure of whether the track is acoustic.'],
            ['Danceability', {{ .AudioFeatures.Danceability }}, 'Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.'],
            ['Energy', {{ .AudioFeatures.Energy }}, 'Energy represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.'],
            ['Instrumentalness', {{ .AudioFeatures.Instrumentalness }}, 'Predicts whether a track contains no vocals. "Ooh" and "aah" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly "vocal".'],
            ['Liveness', {{ .AudioFeatures.Liveness }}, 'Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.'],
            ['Speechiness', {{ .AudioFeatures.Speechiness }}, 'Speechiness detects the presence of spoken words in a track.'],
            ['Valence', {{ .AudioFeatures.Valence }}, 'A measure describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).']
        ]);

        var chart = new google.visualization.BarChart(document.getElementById('chart'));

        chart.draw(data, {
            titlePosition:'none',
            legend: {
                position: 'none'
            },
            hAxis: {
                minValue: 0,
                maxValue: 1,
                format: 'percent'
            }
        });
    }
</script>

{{ template "footer" .}} {{end}}
